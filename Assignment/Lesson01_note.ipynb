{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 复现课堂代码部分：\n",
    "##### 以上部分是采用语言学家使用的语法规则，通过手动的方式编译出来的一套语法。按照词性进行划分的。目的是根据这样的内容，生成一句话，但是如何来做呢？\n",
    "    第一步：在单一的词性中，如果随机选择一个词是adj（只能选择一个词，不可再扩展的叫做终结词terminal）\n",
    "    第二步：在单一的词性中，如果随机选择一个词是adj*，这样的词叫做非终结词，可以扩展。可以出现在等号左边，根据等号左边找到对应右边释义，如果释义的词性仍可扩展，则继续寻找左边（类似于递归调用）\n",
    "    第三步：可以将自定义的语法转化为字典的结构\n",
    "    第四步：根据字符串 =》 产生了具有字典形式的数据结构，如果是不可再扩展的则直接返回句子，如果可以再扩展直接查找左边key值进行循环查找，最终输出句子\n",
    "   以上为rule Based的paradigm，实际上就是自动机，意思是说给丁一个语言规则，以及根据语法规则设计好的一组语法，通过判断是否为终结词进行递归判断，最终生成符合语法结构的话，目前应用比较防范的是在机器语言的编译上面。\n",
    "\n",
    "问题来了：这样一句话是否真的有意义，以及是否符合人类的语言逻辑呢？因为是随机选择的，所以一定会有一些句子是逻辑混乱的，无法根据规则评估生成的句子是否合理\n",
    "Ans：假如定义一些语料库（越大越好），在语料库中抽出任意一个句子，来分析某个字及词出现的概率，以及跟着这个词后面的词出现的概率，这样就每个生成的句子都对应了一个概率值，通过评估每个句子概率值的大小进行评估。\n",
    "$$language\\_model = Probability \\in (0,1)$$\n",
    "$$Pro(w_1 w_2 w_3 w_4) = Pr(w_1|w_2 w_3 w_4) * Pr(w_2| w_3 w_4) * Pr(w_3 | w_4) * Pr(w_4)$$\n",
    "由于计算每个词出现的概率时，需要考虑前面所有出现过的词的概率，计算起来非常复杂，因此可以简化为，每个词出现的概率大小，与前一个词相关性比较强\n",
    "$$Pro(w_1 w_2 w_3 w_4) ~ Pr(w_1 | w_2) * Pr(w_2 | w_3) * Pr(w_3 | w_4) * Pr(w4)$$\n",
    "\n",
    "##### 语言模型 2_gram模型\n",
    "输入：一个句子\n",
    "输出：(0,1)间的值，越接近1，表明句子越真实\n",
    "\n",
    "具体的做法：\n",
    "\n",
    "第一步：在语料库中分析全部自负，组成一个单词出现的频率  \n",
    "　　Step1：倒入语料库  \n",
    "　　Step2：将语料库进行清理，主要去掉invild字符，比如换行符，逗号，分号等）  \n",
    "　　Step3：分词  \n",
    "　　Step4：计算每个分词出现的概率：每个单词在语料库中出现的次数 / 语料库中所有单词出现的次数  \n",
    "第二步：要求一个单词跟另外一个单词的联合概率：两个相邻单词合起来的概率 / 语料库中所有单词出现的次数  \n",
    "第三步：对于一句话的概率来说，可以先进行分词，然后就是相邻两个单词的概率乘起来\n",
    "综上：\n",
    "要评估自动机产生的语句是否合理，可以结合n_gram语言模型进行判断，而不是根据语法进行判断\n",
    "\n",
    "总结：1. 自动机：根据语法结构，终结符和非终结符来循环递归生成一句话，多应用在机器语言的编译  \n",
    "　　　2. N_GRAM模型：N-Gram是一种基于统计语言模型的算法。它的基本思想是将文本里面的内容按照字节进行大小为N的滑动窗口操作，形成了长度是N的字节片段序列。每一个字节片段称为gram，对所有gram的出现频度进行统计，并且按照事先设定好的阈值进行过滤，形成关键gram列表，也就是这个文本的向量特征空间，列表中的每一种gram就是一个特征向量维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Python方法记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1：解释一下这段代码\"random.choice([lambda:\",lambda: adj() + adj_star()])()\" \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans：random.choice([])，从列表中随机选择一个。列表中的元素有两个，分别是lambda：\"和lambda:adj() + adj_star()，这里末尾的括号为了保证函数有执行，去掉括号，返回值是函数本身。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
